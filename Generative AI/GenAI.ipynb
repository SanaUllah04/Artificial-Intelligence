{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfc3895-8507-4ef7-bd85-5d78c37253ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Generative AI VS Discriminative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95621f3c-013b-45e4-89ea-fe798e2381cd",
   "metadata": {},
   "source": [
    "- Discriminative used: Mostly Classification problems (Old and Classic)\n",
    "- Generative Used: Creates and does stuff, more creative (More Modern)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa58022-348a-4353-a811-103ce1c4a321",
   "metadata": {},
   "source": [
    "## LLMS\n",
    "- LLMS are part of **Foundation Models**\n",
    "- A **Foundation Models** can perform different task of each individual model\n",
    "- These are trained in a **Unsuppervised** and on **Unstructed Data**\n",
    "- Hence:\n",
    "- Generative AI -> **Foundation Models** -> LLM's\n",
    "- A GENAI model can perform any task of the pervious Discriminative AI - by providing some specific domain knowledge hence is called - Tunning\n",
    "- GENAI can be specific to a task !\n",
    "- Promting is a small example of using a GENAI to do a specific task.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fa7ee-bb2b-48c3-a4d8-7e9d3647cc17",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b8828-3caf-4676-aa64-02b96ac639cc",
   "metadata": {},
   "source": [
    "- Understanding the human Language.\n",
    "- We have structured and Unstructured Data.\n",
    "- NLP sits in b/w.\n",
    "- Unstructure -> Structure : called = NLU (Natural Lanugage Understanding)\n",
    "- Structure -> UnStructure : called = NLG (Natural Lanugage Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b377f9c-b4a4-472c-805b-6bd1e1b7b38c",
   "metadata": {},
   "source": [
    "#### NLP - NLU: Usecases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c917170b-769b-4689-b1e9-cb79a4d3c34f",
   "metadata": {},
   "source": [
    "- Machine Trnaslation : Context is necessary\n",
    "- ChatBots\n",
    "- Sentiment Analysis\n",
    "- Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e848b461-961e-4edd-8639-bfbaadc63871",
   "metadata": {},
   "source": [
    "#### STEPS\n",
    "- Input (Unstructred TEXT: Or spoken text)\n",
    "- \n",
    "- Input -> Tokens -> Stemming  OR  Lemmatization -> Part of speeach -> N.E.R\n",
    "- \n",
    "- Stemming: running, run, ran -> convert all to (RUN).\n",
    "- Lemmatization: finding a words origin meaning through a dictornary.\n",
    "- Part of speeach: Where to use or put a adverb/adjective etc.\n",
    "- N.E.R: Named entity recognition: is there any body attached to this name ? if = arizona, then= USA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de9838",
   "metadata": {},
   "source": [
    "## In Context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105734a9",
   "metadata": {},
   "source": [
    "- A specific method of Prompt Engineering.\n",
    "- We demonstrate the task to the LLM along with the Prompt.\n",
    "- Hence, no additional training.\n",
    "- Ex: You give prompt along with examples, hence the model will learn about that specific task / prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3a18c",
   "metadata": {},
   "source": [
    "#### Prompt Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada6d69",
   "metadata": {},
   "source": [
    "- Prompts: an instruction/ command given to an LLM, to achieve a desired output/task.\n",
    "- For a prompt we have 2 things, an Instruction + a Context.\n",
    "- Both should be given to an LLM to achieve the desired output.\n",
    "\n",
    "\n",
    "- Prompt Engineering: Designing and refining a promt to communicate better with an LLM.\n",
    "- The concept: Not JUST TO ASK A QUESTION, but how and what is the best form to ask a Question.\n",
    "\n",
    "- So in total there are actullay 4, elements to a prompt:\n",
    "1. Instruction\n",
    "2. Context\n",
    "3. Input-Data\n",
    "4. Output Result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e15c60",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d6632",
   "metadata": {},
   "source": [
    "- A python frame work, specifically build to connect the LLM to AI applications.\n",
    "- There are 4 steps that the Lang chain performs: Retrieve, Extraction, Processing, Generation from large amount of text and multiple sources - Hence, forming a chain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50fbe5",
   "metadata": {},
   "source": [
    "### Benefits:\n",
    "- Modular, Extensible, Decomposition capable and easy intergratable with Vector Data Bases.\n",
    "- Can use external libraries for different types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a82fb1",
   "metadata": {},
   "source": [
    "## Types / Advance Methods of Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bd8cb",
   "metadata": {},
   "source": [
    "## Zero-Short Prompt\n",
    "- Instructing the LLM to perform a task without any prior training or examples provided.\n",
    "Example: \"Humans have 6 figure in their hands - this treatment is true or false\".\n",
    "\n",
    "\n",
    "## One-Short Prompt\n",
    "- Giving an example to the LLM to perform a similar task.\n",
    "\n",
    "\n",
    "## Few-Short Prompt\n",
    "- The LLM learns from a few set of examples before tackling a similar task.\n",
    "\n",
    "\n",
    "## COT- Chain of Thought\n",
    "- Guides LLM through complex reasoning in a step-by-step method.\n",
    "\n",
    "\n",
    "## Self - Consistency\n",
    "- Enhances the reliabililty and accuracy of the outputs.\n",
    "- Generates multiple answers to same questions.\n",
    "- Then, evaulates to determine the most consistent result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5312d6",
   "metadata": {},
   "source": [
    "## Tools & Applications\n",
    "- Playground\n",
    "- LangChain\n",
    "- Hugging Face\n",
    "- IBM AI classroom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e002a",
   "metadata": {},
   "source": [
    "## LCEL Chaining Method.\n",
    "- Builds apps using the pipe operator (|).\n",
    "- Has been updated with new and better pattern.\n",
    "\n",
    "\n",
    "#### - TO Create a LCEL pattern\n",
    "- 1. Define a template with variables inside {}\n",
    "- 2. Create a prompt template\n",
    "- 3. Build a chain using the pipe (|) operator to connect components\n",
    "- 4. Invoke the chain with input values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea122cd",
   "metadata": {},
   "source": [
    "##### Runnable:\n",
    "- An interface or building block which connects components in a pipeline.\n",
    "Such as: LLM , Retrivers, Tools\n",
    "Input -> Runnable -> Output\n",
    "\n",
    "##### Types:\n",
    "1. Runnable Sequence:\n",
    "    Runs each component sequencially and passes output from 1 component as input to the next.\n",
    "2. Runnable Parallel:\n",
    "    Runs multiple components concurrently and uses 1 input for all the components.\n",
    "\n",
    "\n",
    "##### LCEL:\n",
    "- Connecting multiple runnables with a (|) : Pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e7632",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
