{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03216670-b053-4d74-86c1-2f4cfa9e261c",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ccf761-5e60-4740-aa3d-1825cd3a9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fb237-f6f7-4124-8b31-6e29c39e69e6",
   "metadata": {},
   "source": [
    "# Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce03114-6953-4db1-a4b2-169e4ca43f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_dataset(file_path):\n",
    "    dataset = defaultdict(list)     # a dictionary where each key is associated with a list by default.\n",
    "                                    # Key = index, Value = List\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line_num, line in enumerate(file, 1):\n",
    "            line = line.strip()\n",
    "           \n",
    "            # Split the line into parts based on the expected format\n",
    "            parts = line.split(',')\n",
    "            \n",
    "            # The first part is the vertex\n",
    "            vertex = int(parts[0])\n",
    "            \n",
    "            # The last part is the cost\n",
    "            cost = float(parts[-1])\n",
    "            \n",
    "            # Everything in between is the parent set\n",
    "            parent_set_str = ','.join(parts[1:-1])\n",
    "            parent_set = tuple(map(int, parent_set_str.strip('{}').split(','))) if parent_set_str.strip('{}') else ()\n",
    "            \n",
    "            dataset[vertex].append((parent_set, cost))\n",
    "           \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f58bec-fc09-4be8-9257-b7c0f9fddeec",
   "metadata": {},
   "source": [
    "# Computing the Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbfc63d-8b2a-4cfd-9824-4cf6eb548161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cost(ordering, dataset):\n",
    "    total_cost = 0\n",
    "    \n",
    "    # Loop through each vertex in the ordering\n",
    "    for i, vertex in enumerate(ordering):\n",
    "        min_cost = 100000\n",
    "        \n",
    "        # Get all parent sets for this vertex\n",
    "        for parent_set, cost in dataset[vertex]:\n",
    "            \n",
    "            # Check if all parents come before the vertex in the ordering\n",
    "            is_consistent = True\n",
    "            for parent in parent_set:\n",
    "                if parent not in ordering[:i]:\n",
    "                    is_consistent = False\n",
    "                    break\n",
    "            \n",
    "            # If consistent, update the minimum cost\n",
    "            if is_consistent:\n",
    "                min_cost = min(min_cost, cost)\n",
    "        \n",
    "        # Add the minimum cost to the total\n",
    "        if min_cost != 100000:\n",
    "            total_cost += min_cost\n",
    "        else:\n",
    "            # If no consistent parent set, this is not a valid ordering\n",
    "            return 100000\n",
    "    \n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1829c-82ba-45a6-90e3-a3b2fa8015ac",
   "metadata": {},
   "source": [
    "# Hill Climber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c4c980-ba03-41e8-90e3-56e36f9eeb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hill_climbing(dataset, max_iterations=1000):\n",
    "    vertices = list(dataset.keys())\n",
    "\n",
    "    \n",
    "    # Start with a random ordering\n",
    "    current_order = list(vertices)\n",
    "    random.shuffle(current_order)\n",
    "    current_cost = compute_cost(current_order, dataset)\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        improved = False\n",
    "        \n",
    "        # Try swapping each pair of vertices\n",
    "        for i in range(len(vertices)):\n",
    "            for j in range(i + 1, len(vertices)):\n",
    "                \n",
    "                # Create a new ordering by swapping two vertices\n",
    "                new_order = current_order.copy()\n",
    "                new_order[i], new_order[j] = new_order[j], new_order[i]\n",
    "                new_cost = compute_cost(new_order, dataset)\n",
    "                \n",
    "                # If better, keep it\n",
    "                if new_cost < current_cost:\n",
    "                    current_order, current_cost = new_order, new_cost\n",
    "                    improved = True\n",
    "                    break\n",
    "            if improved:\n",
    "                break\n",
    "        \n",
    "        # If no improvement was found, we're at a local optimum\n",
    "        if not improved:\n",
    "            break\n",
    "    \n",
    "    return current_order, current_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac77da3-de67-4591-8ff9-529e2dea0cba",
   "metadata": {},
   "source": [
    "# Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c59d15-455f-4d4c-aa91-b6388cf4461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulated_annealing(dataset, max_iterations=1000, decay_factor=0.99, initial_probability=1):\n",
    "    vertices = list(dataset.keys())\n",
    "    \n",
    "    # Start with a random ordering\n",
    "    current_order = list(vertices)\n",
    "    random.shuffle(current_order)\n",
    "    current_cost = compute_cost(current_order, dataset)\n",
    "    \n",
    "    best_order = current_order.copy()\n",
    "    best_cost = current_cost\n",
    "    \n",
    "    probability = initial_probability\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        \n",
    "        # Generate a neighbor by swapping two random vertices\n",
    "        i, j = random.sample(range(len(vertices)), 2)\n",
    "        new_order = current_order.copy()\n",
    "        new_order[i], new_order[j] = new_order[j], new_order[i]\n",
    "        new_cost = compute_cost(new_order, dataset)\n",
    "        \n",
    "        # Decide whether to accept the new solution\n",
    "        if new_cost < current_cost or random.random() < probability:\n",
    "            current_order, current_cost = new_order, new_cost\n",
    "            \n",
    "            # Update best solution if better\n",
    "            if current_cost < best_cost:\n",
    "                best_order, best_cost = current_order.copy(), current_cost\n",
    "        \n",
    "        # Reduce the probability of accepting worse solutions over time\n",
    "        probability *= decay_factor\n",
    "        \n",
    "        # Stop if the probability becomes too low\n",
    "        if probability < 0.01:\n",
    "            break\n",
    "    \n",
    "    return best_order, best_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a434ee-2b1f-4766-a7a7-c759cb8d2ad8",
   "metadata": {},
   "source": [
    "# Greedy Best First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb796380-8d55-4e21-9d35-5139dee2f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_search(dataset):\n",
    "    vertices = list(dataset.keys())\n",
    "    ordering = []\n",
    "    remaining_vertices = set(vertices)\n",
    "    \n",
    "    while remaining_vertices:\n",
    "        best_vertex = None\n",
    "        best_cost = 100000\n",
    "        \n",
    "        # Find the best vertex to add next\n",
    "        for vertex in remaining_vertices:\n",
    "            min_cost = 100000\n",
    "            for parent_set, cost in dataset[vertex]:\n",
    "                \n",
    "                # Check if all parents are already in our ordering\n",
    "                if all(parent in ordering for parent in parent_set):\n",
    "                    min_cost = min(min_cost, cost)\n",
    "            \n",
    "            if min_cost < best_cost:\n",
    "                best_cost = min_cost\n",
    "                best_vertex = vertex\n",
    "        \n",
    "        # Add the best vertex to our ordering\n",
    "        ordering.append(best_vertex)\n",
    "        remaining_vertices.remove(best_vertex)\n",
    "    \n",
    "    final_cost = compute_cost(ordering, dataset)\n",
    "    return ordering, final_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631c3d3-bbb4-4f58-ad85-400c6e31aeeb",
   "metadata": {},
   "source": [
    "# Comparing All the Algo's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebbfcfc-85b9-44f8-94e6-dadfb04c71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all algorithms and find the best result\n",
    "\n",
    "                        # File       # File Name\n",
    "def compare_algorithms(dataset_path, dataset_name):\n",
    "    print(f\"\\nAnalyzing {dataset_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = read_dataset(dataset_path)\n",
    "    print(f\"Dataset has {len(dataset)} vertices\")\n",
    "    \n",
    "    # Run each algorithm\n",
    "    greedy_order, greedy_cost = greedy_search(dataset)\n",
    "    print(f\"1. Greedy Search: Cost = {greedy_cost}\")\n",
    "    \n",
    "    hc_order, hc_cost = hill_climbing(dataset)\n",
    "    print(f\"2. Hill Climbing: Cost = {hc_cost}\")\n",
    "    \n",
    "    sa_order, sa_cost = simulated_annealing(dataset)\n",
    "    print(f\"3. Simulated Annealing: Cost = {sa_cost}\")\n",
    "    \n",
    "    # Find the best algorithm\n",
    "    if greedy_cost <= hc_cost and greedy_cost <= sa_cost:\n",
    "        best_algo = \"Greedy Search\"\n",
    "        best_order = greedy_order\n",
    "        best_cost = greedy_cost\n",
    "        \n",
    "    elif hc_cost <= greedy_cost and hc_cost <= sa_cost:\n",
    "        best_algo = \"Hill Climbing\"\n",
    "        best_order = hc_order\n",
    "        best_cost = hc_cost\n",
    "        \n",
    "    else:\n",
    "        best_algo = \"Simulated Annealing\"\n",
    "        best_order = sa_order\n",
    "        best_cost = sa_cost\n",
    "    \n",
    "    print(f\"\\nBest result: {best_algo} with cost {best_cost}\")\n",
    "    print(f\"Best ordering: {best_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c933c92-8b50-464f-b11e-e753c6d5b60f",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84601db5-fdac-4bdd-8e3b-4c21c0a58b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Dataset 1\n",
      "----------------------------------------\n",
      "Dataset has 5 vertices\n",
      "1. Greedy Search: Cost = 465.43499999999995\n",
      "2. Hill Climbing: Cost = 465.43399999999997\n",
      "3. Simulated Annealing: Cost = 465.43399999999997\n",
      "\n",
      "Best result: Hill Climbing with cost 465.43399999999997\n",
      "Best ordering: [4, 2, 5, 3, 1]\n",
      "\n",
      "Analyzing Dataset 2\n",
      "----------------------------------------\n",
      "Dataset has 18 vertices\n",
      "1. Greedy Search: Cost = 3243.777\n",
      "2. Hill Climbing: Cost = 3196.095\n",
      "3. Simulated Annealing: Cost = 3194.8370000000004\n",
      "\n",
      "Best result: Simulated Annealing with cost 3194.8370000000004\n",
      "Best ordering: [1, 4, 5, 13, 11, 8, 6, 18, 12, 10, 3, 2, 7, 17, 16, 15, 9, 14]\n",
      "\n",
      "Analyzing Dataset 3\n",
      "----------------------------------------\n",
      "Dataset has 19 vertices\n",
      "1. Greedy Search: Cost = 1993.182\n",
      "2. Hill Climbing: Cost = 1972.6349999999995\n",
      "3. Simulated Annealing: Cost = 1975.2910000000002\n",
      "\n",
      "Best result: Hill Climbing with cost 1972.6349999999995\n",
      "Best ordering: [1, 8, 14, 10, 9, 11, 6, 13, 7, 3, 12, 19, 16, 17, 4, 5, 18, 2, 15]\n",
      "\n",
      "Analyzing Dataset 4\n",
      "----------------------------------------\n",
      "Dataset has 19 vertices\n",
      "1. Greedy Search: Cost = 8111.977000000001\n",
      "2. Hill Climbing: Cost = 7969.542999999999\n",
      "3. Simulated Annealing: Cost = 8007.971\n",
      "\n",
      "Best result: Hill Climbing with cost 7969.542999999999\n",
      "Best ordering: [9, 12, 11, 18, 8, 17, 1, 13, 2, 19, 16, 14, 5, 15, 10, 6, 7, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define datasets\n",
    "datasets = [\n",
    "    (\"data0.txt\", \"Dataset 1\"),\n",
    "    (\"data1.txt\", \"Dataset 2\"),\n",
    "    (\"data2.txt\", \"Dataset 3\"),\n",
    "    (\"data3.txt\", \"Dataset 4\")\n",
    "]\n",
    "\n",
    "\n",
    "# Sending to Compare each dataset\n",
    "for file_path, name in datasets:\n",
    "    compare_algorithms(file_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f3196-03fc-4364-b3ee-40a56e7e1846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
